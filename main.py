import streamlit as st
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
# from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import os
from PIL import Image

import torch
import torchvision
import torchvision.transforms as transforms

import torch.nn as nn
from torchvision import transforms as T
import torchvision.models as models
import time
import requests
from io import BytesIO



def page_about_model2():

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    st.title('üìä –ê–Ω–∞–ª–∏–∑ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏')

    st.header('üìÇ –°–æ—Å—Ç–∞–≤ –¥–∞—Ç–∞—Å–µ—Ç–∞')

    train_class_counts = {'sunflower': 17,
    'vigna-radiati(Mung)': 20,
    'jowar': 22,
    'almond': 15,
    'papaya': 16,
    'mustard-oil': 20,
    'rice': 23,
    'pineapple': 18,
    'tomato': 20,
    'Tobacco-plant': 27,
    'cotton': 24,
    'gram': 17,
    'banana': 25,
    'coconut': 18,
    'maize': 25,
    'Olive-tree': 23,
    'soyabean': 24,
    'sugarcane': 19,
    'jute': 16,
    'clove': 23,
    'wheat': 21,
    'chilli': 17,
    'Fox_nut(Makhana)': 16,
    'cardamom': 16,
    'Lemon': 21,
    'tea': 17,
    'Pearl_millet(bajra)': 39,
    'Cucumber': 24,
    'Cherry': 25,
    'Coffee-plant': 22}

    valid_class_counts = {'banana': 6,
    'clove': 7,
    'almond': 6,
    'chilli': 6,
    'cardamom': 6,
    'Cherry': 7,
    'coconut': 7,
    'Coffee-plant': 7,
    'Cucumber': 7,
    'Fox_nut(Makhana)': 7,
    'jute': 7,
    'jowar': 8,
    'Lemon': 7,
    'maize': 6,
    'papaya': 7,
    'mustard-oil': 8,
    'pineapple': 7,
    'gram': 8,
    'soyabean': 6,
    'sunflower': 7,
    'rice': 6,
    'Olive-tree': 7,
    'sugarcane': 6,
    'Pearl_millet(bajra)': 8,
    'cotton': 8,
    'tea': 6,
    'tomato': 6,
    'Tobacco-plant': 6,
    'vigna-radiati(Mung)': 7,
    'wheat': 10}

    plt.style.use('seaborn-v0_8')

    # –°–æ–∑–¥–∞–µ–º –¥–≤–∞ —Å—Ç–æ–ª–±—Ü–∞
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Train Dataset")
        fig1, ax1 = plt.subplots(figsize=(16, 10))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã –¥–ª—è —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        sorted_train = dict(sorted(train_class_counts.items(), key=lambda x: x[1], reverse=True))
        
        # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Å–∏–≤—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç —Ü–≤–µ—Ç–æ–≤
        colors = plt.cm.viridis(np.linspace(0, 1, len(sorted_train)))
        
        bars = ax1.bar(range(len(sorted_train)), sorted_train.values(), color=colors, alpha=0.8, edgecolor='black', linewidth=0.5)
        ax1.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π', fontsize=12, fontweight='bold')
        ax1.set_title(f'üì¶ Train Dataset: {sum(train_class_counts.values())} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π', 
                    fontsize=14, fontweight='bold', pad=20)
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–µ—Ç–∫–∏ –Ω–∞ –æ—Å–∏ X
        plt.xticks(range(len(sorted_train)), list(sorted_train.keys()), 
                rotation=90, fontsize=9, ha='center')
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for i, (bar, count) in enumerate(zip(bars, sorted_train.values())):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, 
                    f'{count}', ha='center', va='bottom', fontsize=8, fontweight='bold')
        
        # –£–ª—É—á—à–∞–µ–º –≤–Ω–µ—à–Ω–∏–π –≤–∏–¥
        ax1.grid(axis='y', alpha=0.3, linestyle='--')
        ax1.set_axisbelow(True)
    # ax1.yaxis.set_major_locator(MaxNLocator(integer=True))
        plt.tight_layout()
        
        st.pyplot(fig1)

    with col2:
        st.subheader("Valid Dataset")
        fig2, ax2 = plt.subplots(figsize=(16, 10))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã –¥–ª—è —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        sorted_valid = dict(sorted(valid_class_counts.items(), key=lambda x: x[1], reverse=True))
        
        # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Å–∏–≤—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç —Ü–≤–µ—Ç–æ–≤ (–¥—Ä—É–≥–æ–π —Ü–≤–µ—Ç–æ–≤–æ–π —Å—Ö–µ–º—ã)
        colors = plt.cm.plasma(np.linspace(0, 1, len(sorted_valid)))
        
        bars = ax2.bar(range(len(sorted_valid)), sorted_valid.values(), color=colors, alpha=0.8, edgecolor='black', linewidth=0.5)
        ax2.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π', fontsize=12, fontweight='bold')
        ax2.set_title(f'‚úÖ Valid Dataset: {sum(valid_class_counts.values())} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π', 
                    fontsize=14, fontweight='bold', pad=20)
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–µ—Ç–∫–∏ –Ω–∞ –æ—Å–∏ X
        plt.xticks(range(len(sorted_valid)), list(sorted_valid.keys()), 
                rotation=90, fontsize=9, ha='center')
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for i, (bar, count) in enumerate(zip(bars, sorted_valid.values())):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2, 
                    f'{count}', ha='center', va='bottom', fontsize=8, fontweight='bold')
        
        # –£–ª—É—á—à–∞–µ–º –≤–Ω–µ—à–Ω–∏–π –≤–∏–¥
        ax2.grid(axis='y', alpha=0.3, linestyle='--')
        ax2.set_axisbelow(True)
        # ax2.yaxis.set_major_locator(MaxNLocator(integer=True))
        plt.tight_layout()
        
        st.pyplot(fig2)

    # –ö—Ä–∞—Å–∏–≤–∞—è –∏—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    st.divider()

    # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Å–∏–≤—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    st.markdown("""
    <div style='background-color: #f0f2f6; padding: 20px; border-radius: 10px; border-left: 5px solid #4CAF50;'>
        <h3 style='color: #2E86AB; margin-bottom: 20px;'>üìà –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö</h3>
    """, unsafe_allow_html=True)

    # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)

    with stat_col1:
        st.metric("üéØ –í—Å–µ–≥–æ –∫–ª–∞—Å—Å–æ–≤", len(train_class_counts), delta=None)

    with stat_col2:
        total_train = sum(train_class_counts.values())
        st.metric("üì¶ Train –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", total_train, delta=None)

    with stat_col3:
        total_valid = sum(valid_class_counts.values())
        st.metric("‚úÖ Valid –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", total_valid, delta=None)

    with stat_col4:
        total_all = total_train + total_valid
        st.metric("üìä –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", total_all, delta=None)

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    st.markdown("---")
    col5, col6 = st.columns(2)

    with col5:
        st.write("**üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –Ω–∞–±–æ—Ä–∞–º:**")
        train_percent = round((total_train / total_all) * 100, 1)
        valid_percent = round((total_valid / total_all) * 100, 1)
        st.write(f"- Train: {train_percent}% ({total_train} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)")
        st.write(f"- Valid: {valid_percent}% ({total_valid} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)")

    with col6:
        st.write("**üìã –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º:**")
        avg_per_class = round(total_all / len(train_class_counts), 1)
        st.write(f"- –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {avg_per_class} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π/–∫–ª–∞—Å—Å")
        st.write(f"- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ: {max(train_class_counts.values())} (Train), {max(valid_class_counts.values())} (Valid)")
        st.write(f"- –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ: {min(train_class_counts.values())} (Train), {min(valid_class_counts.values())} (Valid)")

    st.markdown("</div>", unsafe_allow_html=True)

    ### –î–∞–Ω–Ω—ã–µ —Å –∫—Ä–∏–≤—ã–º–∏ –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏

    st.set_page_config(layout="wide")

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    st.title("üìà –ö—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")

    learning_curves = "images/learning_curves.png"
    metrics_file = "images/metrics.png"

    if os.path.exists(learning_curves) and os.path.exists(metrics_file):
        col1, col2 = st.columns(2)
        
        with col1:
            st.image(Image.open(learning_curves), caption="–ö—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è")
            
        with col2:
            st.image(Image.open(metrics_file), caption="–ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏")
            
            # –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            st.subheader("üìä –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏")
            st.metric("Final Train Accuracy", "0.884")
            st.metric("Final Valid Accuracy", "0.761")
        
    else:
        st.error(f"–§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç–∏:")
        st.write(f"–ü—É—Ç—å –∫ –∫—Ä–∏–≤—ã–º: {os.path.abspath(learning_curves)}")
        st.write(f"–ü—É—Ç—å –∫ –º–µ—Ç—Ä–∏–∫–∞–º: {os.path.abspath(metrics_file)}")
        st.write(f"–¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}")

    ### –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è

    st.title("üïî –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è")
    st.write(f"**–û–±—â–µ–µ –≤—Ä–µ–º—è:** 10 –º–∏–Ω—É—Ç")
    st.write(f"üìä –≠–ø–æ—Ö: 10 | –ë–∞—Ç—á–µ–π: 128")

    # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫


    st.set_page_config(layout="wide")
    st.title("üíº –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫")

    matrix = 'images/confusion_matrix.png'
    st.image(Image.open(matrix), caption="–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫")


def page_pred_model2():
    CLASSES = ['Cherry', 'Coffee-plant', 'Cucumber', 'Fox_nut(Makhana)', 
               'Lemon', 'Olive-tree', 'Pearl_millet(bajra)', 'Tobacco-plant', 
               'almond', 'banana', 'cardamom', 'chilli', 'clove', 'coconut', 
               'cotton', 'gram', 'jowar', 'jute', 'maize', 'mustard-oil', 'papaya', 
               'pineapple', 'rice', 'soyabean', 'sugarcane', 'sunflower', 'tea', 'tomato', 
               'vigna-radiati(Mung)', 'wheat']

    @st.cache_resource

    
    def load_model():
        torch.serialization.add_safe_globals([torch.nn.modules.container.Sequential])
        return torch.load('models/my_torch_model_full.pth', map_location='cpu', weights_only=False)

    model = load_model()

    st.title("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫—É–ª—å—Ç—É—Ä—ã –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞")
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∫–∞—Ä—Ç–∏–Ω–∫—É", type=["png", "jpg", "jpeg"])

    url = st.text_input("–ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:", "")

    if uploaded_file:
        image = Image.open(uploaded_file).convert('RGB')
        st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∫–∞', use_container_width=True)

        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])
        input_tensor = transform(image).unsqueeze(0)  # –†–∞–∑–º–µ—Ä (1,3,224,224)

    if url:
        response = requests.get(url)
        response.raise_for_status()  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—à–∏–±–∫–∏ HTTP
        image = Image.open(BytesIO(response.content))

        transform = transforms.Compose([
            transforms.Resize((224, 224)),  # –ø—Ä–æ–≤–µ—Ä—å—Ç–µ, –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ —ç—Ç–æ—Ç —Ä–∞–∑–º–µ—Ä
            transforms.ToTensor(),
        ])
        input_tensor = transform(image).unsqueeze(0)  # –†–∞–∑–º–µ—Ä (1,3,224,224)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        try:
            with torch.no_grad():
                outputs = model(input_tensor)
                
                # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
                probabilities = torch.nn.functional.softmax(outputs, dim=1)
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-3 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                top3_probs, top3_indices = torch.topk(probabilities, 3)
                
                st.write(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {CLASSES[top3_indices[0][0].item()]}")
                st.write("–¢–æ–ø-3 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
                
                for i in range(3):
                    class_idx = top3_indices[0][i].item()
                    prob = top3_probs[0][i].item()
                    st.write(f"{i+1}. {CLASSES[class_idx]}: {prob:.4f} ({prob*100:.2f}%)")
        
        except Exception as e:
            st.write(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")

def page_pred_model1():
    CLASSES1 = ["Dark", "Green", "Light", "Medium"]

    @st.cache_resource
    def load_model1():
        return torch.load('models/coffee-beans_model.pt', map_location='cpu', weights_only=False)

    model1 = load_model1()

    st.title("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–µ—Ä–Ω–∞ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞")
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∫–∞—Ä—Ç–∏–Ω–∫—É", type=["png", "jpg", "jpeg"])

    url = st.text_input("–ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:", "")

    if uploaded_file:
        image = Image.open(uploaded_file).convert('RGB')
        st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∫–∞', use_container_width=True)

        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        transform = transforms.Compose([
            transforms.Resize((224, 224)),  # –ø—Ä–æ–≤–µ—Ä—å—Ç–µ, –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ —ç—Ç–æ—Ç —Ä–∞–∑–º–µ—Ä
            transforms.ToTensor(),
        ])
        input_tensor = transform(image).unsqueeze(0)  # –†–∞–∑–º–µ—Ä (1,3,224,224)

    if url:
        response = requests.get(url)
        response.raise_for_status()  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—à–∏–±–∫–∏ HTTP
        image = Image.open(BytesIO(response.content))

        transform = transforms.Compose([
            transforms.Resize((224, 224)),  # –ø—Ä–æ–≤–µ—Ä—å—Ç–µ, –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ —ç—Ç–æ—Ç —Ä–∞–∑–º–µ—Ä
            transforms.ToTensor(),
        ])
        input_tensor = transform(image).unsqueeze(0)  # –†–∞–∑–º–µ—Ä (1,3,224,224)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)



        try:
            with torch.no_grad():
                outputs = model1(input_tensor)
                
                # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
                probabilities = torch.nn.functional.softmax(outputs, dim=1)
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-3 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                top3_probs, top3_indices = torch.topk(probabilities, 3)
                
                st.write(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {CLASSES1[top3_indices[0][0].item()]}")
                st.write("–¢–æ–ø-3 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
                
                for i in range(3):
                    class_idx = top3_indices[0][i].item()
                    prob = top3_probs[0][i].item()
                    st.write(f"{i+1}. {CLASSES1[class_idx]}: {prob:.4f} ({prob*100:.2f}%)")
        
        except Exception as e:
            st.write(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")

def about_model1():
    # ===== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –°–¢–†–ê–ù–ò–¶–´ =====
    st.set_page_config(
        page_title="Coffee Beans Model Training Report", page_icon="‚òï", layout="wide"
    )

    # ===== –ó–ê–ì–û–õ–û–í–û–ö =====
    st.title("üóÇÔ∏è –û—Ç—á—ë—Ç –æ–± –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫–æ—Ñ–µ–π–Ω—ã—Ö –∑—ë—Ä–µ–Ω")
    st.markdown("---")

    # ===== –†–ê–ó–î–ï–õ 1: –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–û–î–ï–õ–ò =====
    st.header("üîç –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞", "ShuffleNetV2 x1.0")
        st.caption("Pretrained –Ω–∞ ImageNet")
    with col2:
        st.metric("–í—Å–µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤", "~1.2M")
        st.caption("–û–±—É—á–∞–µ–º—ã—Ö: 4,100 (—Ç–æ–ª—å–∫–æ fc)")
    with col3:
        st.metric("–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏", "4.82 MB")
        st.caption("+ 1.3 GB –∞–∫—Ç–∏–≤–∞—Ü–∏–π")

    st.markdown(
        "**–°—Ç—Ä–∞—Ç–µ–≥–∏—è –æ–±—É—á–µ–Ω–∏—è:** Transfer Learning (–∑–∞–º–æ—Ä–æ–∂–µ–Ω—ã –≤—Å–µ —Å–ª–æ–∏ –∫—Ä–æ–º–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ)"
    )

    # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏
    with st.expander("üìê –î–µ—Ç–∞–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏"):
        st.code(
            """
    ShuffleNetV2(
    (conv1): Conv2d(3 ‚Üí 24, kernel=3√ó3, stride=2)
    (maxpool): MaxPool2d(kernel=3, stride=2)
    (stage2): 4√ó InvertedResidual (24 ‚Üí 58 –∫–∞–Ω–∞–ª–æ–≤)
    (stage3): 8√ó InvertedResidual (58 ‚Üí 232 –∫–∞–Ω–∞–ª–æ–≤)
    (stage4): 4√ó InvertedResidual (232 ‚Üí 464 –∫–∞–Ω–∞–ª–æ–≤)
    (conv5): Conv2d(464 ‚Üí 1024, kernel=1√ó1)
    (fc): Linear(1024 ‚Üí 4 –∫–ª–∞—Å—Å–∞) ‚Üê –û–ë–£–ß–ê–ï–ú–´–ô
    )
        """,
            language="text",
        )

    st.markdown("---")

    # ===== –†–ê–ó–î–ï–õ 2: –°–û–°–¢–ê–í –î–ê–¢–ê–°–ï–¢–ê =====
    st.header("üì¶ –°–æ—Å—Ç–∞–≤ –¥–∞—Ç–∞—Å–µ—Ç–∞")

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "1,600")
    with col2:
        st.metric("Train", "1,200 (75%)")
    with col3:
        st.metric("Validation", "400 (25%)")
    with col4:
        st.metric("–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "224√ó224")

    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º
    st.subheader("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º")
    class_distribution = pd.DataFrame(
        {
            "–ö–ª–∞—Å—Å": ["Dark", "Green", "Light", "Medium"],
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤": [400, 400, 400, 400],
            "–ü—Ä–æ—Ü–µ–Ω—Ç": ["25%", "25%", "25%", "25%"],
        }
    )

    col1, col2 = st.columns([2, 1])
    with col1:
        fig, ax = plt.subplots(figsize=(8, 4))
        colors = ["#8B4513", "#228B22", "#F4A460", "#D2691E"]
        ax.bar(
            class_distribution["–ö–ª–∞—Å—Å"],
            class_distribution["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤"],
            color=colors,
        )
        ax.set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        ax.set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ –∫–ª–∞—Å—Å–∞–º")
        ax.set_ylim(0, 500)
        for i, v in enumerate(class_distribution["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤"]):
            ax.text(i, v + 10, str(v), ha="center", fontweight="bold")
        st.pyplot(fig)
        plt.close()

    with col2:
        st.dataframe(class_distribution, hide_index=True, use_container_width=True)

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    with st.expander("‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö"):
        st.markdown(
            """
        **–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:**
        - `Resize(224√ó224)`
        - `RandomRotation(45¬∞)`
        - `RandomHorizontalFlip()`
        - `ToTensor()`
        - `Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])`
        
        **–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏:**
        - `Resize(224√ó224)`
        - `ToTensor()`
        - `Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])`
        
        **DataLoader:**
        - Batch size: 64
        - Num_classes: 4
        """
        )

    st.markdown("---")

    # ===== –†–ê–ó–î–ï–õ 3: –ü–ê–†–ê–ú–ï–¢–†–´ –û–ë–£–ß–ï–ù–ò–Ø =====
    st.header("üéì –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è")

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("–≠–ø–æ—Ö–∏", "5 / 5")
    with col2:
        st.metric("Learning Rate", "0.005")
        st.caption("–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: Adam")
    with col3:
        st.metric("Loss Function", "CrossEntropyLoss")
    with col4:
        st.metric("Batch Size", "64")

    st.markdown("---")

    # ===== –†–ê–ó–î–ï–õ 4: –ö–†–ò–í–´–ï –û–ë–£–ß–ï–ù–ò–Ø =====
    st.header("üìà –ö—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è")

    # –î–∞–Ω–Ω—ã–µ –∏–∑ –æ–±—É—á–µ–Ω–∏—è (–∏–∑ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ ‚Ññ8)
    train_losses = [1.2666, 1.0626, 0.9233, 0.7460, 0.3386]
    valid_losses = [1.2313, 1.0458, 0.9217, 0.7668, 0.6890]
    train_accs = [0.7023, 0.8460, 0.8913, 0.9518, 0.9055]
    valid_accs = [0.7746, 0.8584, 0.9001, 0.9665, 0.9598]
    epochs = list(range(5))

    col1, col2 = st.columns(2)

    with col1:
        # –ì—Ä–∞—Ñ–∏–∫ Loss
        fig, ax = plt.subplots(figsize=(8, 5))
        ax.plot(
            epochs,
            train_losses,
            marker="o",
            linewidth=2,
            label="Train Loss",
            color="#1f77b4",
        )
        ax.plot(
            epochs,
            valid_losses,
            marker="s",
            linewidth=2,
            label="Valid Loss",
            color="#ff7f0e",
        )
        ax.set_xlabel("–≠–ø–æ—Ö–∞", fontsize=12)
        ax.set_ylabel("Loss", fontsize=12)
        ax.set_title("Loss History", fontsize=14, fontweight="bold")
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        st.pyplot(fig)
        plt.close()

    with col2:
        # –ì—Ä–∞—Ñ–∏–∫ Accuracy
        fig, ax = plt.subplots(figsize=(8, 5))
        ax.plot(
            epochs,
            train_accs,
            marker="o",
            linewidth=2,
            label="Train Accuracy",
            color="#1f77b4",
        )
        ax.plot(
            epochs,
            valid_accs,
            marker="s",
            linewidth=2,
            label="Valid Accuracy",
            color="#ff7f0e",
        )
        ax.set_xlabel("–≠–ø–æ—Ö–∞", fontsize=12)
        ax.set_ylabel("Accuracy", fontsize=12)
        ax.set_title("Accuracy History", fontsize=14, fontweight="bold")
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0.6, 1.0)
        st.pyplot(fig)
        plt.close()

    # –ú–µ—Ç—Ä–∏–∫–∏ –≤ —Ç–∞–±–ª–∏—á–Ω–æ–º –≤–∏–¥–µ
    st.subheader("üìä –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ —ç–ø–æ—Ö–∞–º")
    metrics_df = pd.DataFrame(
        {
            "–≠–ø–æ—Ö–∞": [f"Epoch {i:02d}" for i in epochs],
            "Train Loss": train_losses,
            "Valid Loss": valid_losses,
            "Train Accuracy": [f"{acc:.2%}" for acc in train_accs],
            "Valid Accuracy": [f"{acc:.2%}" for acc in valid_accs],
        }
    )
    st.dataframe(metrics_df, hide_index=True, use_container_width=True)

    # –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Final Train Loss", f"{train_losses[-1]:.4f}")
    with col2:
        st.metric("Final Valid Loss", f"{valid_losses[-1]:.4f}")
    with col3:
        st.metric("Final Train Accuracy", f"{train_accs[-1]:.2%}")
    with col4:
        st.metric("Final Valid Accuracy", f"{valid_accs[-1]:.2%}", delta="+19.52%")

    st.info(
        "üí° **–ù–∞–±–ª—é–¥–µ–Ω–∏–µ:** Validation accuracy –≤—ã—à–µ train accuracy ‚Äî –ø—Ä–∏–∑–Ω–∞–∫ —Ö–æ—Ä–æ—à–µ–π –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏!"
    )

    st.markdown("---")

    # ===== –†–ê–ó–î–ï–õ 5: –ú–ï–¢–†–ò–ö–ò –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò =====
    st.header("üéØ –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")

    st.subheader("üìã Classification Report")

    # –î–∞–Ω–Ω—ã–µ –±–µ–∑ —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏
    report_data = {
        "Class": ["Dark", "Green", "Light", "Medium", "", "Weighted Avg"],
        "Precision": [0.97, 0.95, 0.94, 0.98, None, 0.96],
        "Recall": [0.96, 0.97, 0.93, 0.96, None, 0.96],
        "F1-Score": [0.96, 0.96, 0.94, 0.97, None, 0.96],
        "Support": [100, 100, 100, 100, None, 400],
    }
    report_df = pd.DataFrame(report_data)

    # –ü—Ä–æ—Å—Ç–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–µ–∑ —Å—Ç–∏–ª–µ–π
    st.dataframe(report_df, hide_index=True, use_container_width=True)

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ–∏–∫ (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞)
    fig, ax = plt.subplots(figsize=(10, 5))
    classes_only = report_df[report_df["Class"].isin(["Dark", "Green", "Light", "Medium"])]
    x = np.arange(len(classes_only))
    width = 0.25

    ax.bar(x - width, classes_only["Precision"], width, label="Precision", color="#1f77b4")
    ax.bar(x, classes_only["Recall"], width, label="Recall", color="#ff7f0e")
    ax.bar(x + width, classes_only["F1-Score"], width, label="F1-Score", color="#2ca02c")

    ax.set_xlabel("Class")
    ax.set_ylabel("Score")
    ax.set_title("–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º")
    ax.set_xticks(x)
    ax.set_xticklabels(classes_only["Class"])
    ax.legend()
    ax.set_ylim(0.9, 1.0)
    ax.grid(axis="y", alpha=0.3)

    st.pyplot(fig)
    plt.close()


    # –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Weighted Precision", "0.9600")
    with col2:
        st.metric("Weighted Recall", "0.9598")
    with col3:
        st.metric("Weighted F1-Score", "0.9599")

    st.markdown("---")

    # ===== –†–ê–ó–î–ï–õ 7: –í–†–ï–ú–Ø –û–ë–£–ß–ï–ù–ò–Ø =====
    st.header("‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("–û–±—â–µ–µ –≤—Ä–µ–º—è", "~93 —Å–µ–∫—É–Ω–¥")
        st.caption("‚âà 1 –º–∏–Ω—É—Ç–∞ 33 —Å–µ–∫—É–Ω–¥—ã")
    with col2:
        st.metric("–í—Ä–µ–º—è –Ω–∞ —ç–ø–æ—Ö—É", "~18.6 —Å–µ–∫")
        st.caption("–°—Ä–µ–¥–Ω–µ–µ –ø–æ 5 —ç–ø–æ—Ö–∞–º")
    with col3:
        st.metric("–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ", "CUDA")
        st.caption("GPU-—É—Å–∫–æ—Ä–µ–Ω–∏–µ")

    st.markdown("---")

    # ===== FOOTER =====
    st.success("‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é! Validation Accuracy: **95.98%**")

    with st.expander("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"):
        st.code(
            """
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏
    torch.save(model.state_dict(), "coffee-beans_model.pt")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model = models.shufflenet_v2_x1_0(pretrained=False)
    model.fc = nn.Linear(1024, 4)
    model.load_state_dict(torch.load("coffee-beans_model.pt"))
    model.eval()
        """,
            language="python",
        )   



page = st.sidebar.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É", [ '—Å—Ç—Ä.1- –ü—Ä–æ –º–æ–¥–µ–ª—å "–°—Ç–µ–ø–µ–Ω—å –ø—Ä–æ–∂–∞—Ä–∫–∏ –∑–µ—Ä—ë–Ω"', '—Å—Ç—Ä.2- –ü—Ä–æ –º–æ–¥–µ–ª—å "–°–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫—É–ª—å—Ç—É—Ä—ã"', 
                                              '—Å—Ç—Ä.3- –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ "–°—Ç–µ–ø–µ–Ω—å –ø—Ä–æ–∂–∞—Ä–∫–∏ –∑–µ—Ä—ë–Ω"', '—Å—Ç—Ä.4- –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ "–°–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫—É–ª—å—Ç—É—Ä—ã"'])

# –í—ã–∑–æ–≤ –Ω—É–∂–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É
if page == '—Å—Ç—Ä.2- –ü—Ä–æ –º–æ–¥–µ–ª—å "–°–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫—É–ª—å—Ç—É—Ä—ã"':
    page_about_model2()
elif page == '—Å—Ç—Ä.4- –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ "–°–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫—É–ª—å—Ç—É—Ä—ã"':
    page_pred_model2()
elif page == '—Å—Ç—Ä.3- –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ "–°—Ç–µ–ø–µ–Ω—å –ø—Ä–æ–∂–∞—Ä–∫–∏ –∑–µ—Ä—ë–Ω"':
    page_pred_model1()
elif page == '—Å—Ç—Ä.1- –ü—Ä–æ –º–æ–¥–µ–ª—å "–°—Ç–µ–ø–µ–Ω—å –ø—Ä–æ–∂–∞—Ä–∫–∏ –∑–µ—Ä—ë–Ω"':
    about_model1()

